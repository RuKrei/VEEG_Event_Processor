{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bitmegconda588718a20d4e488692bc9bad2748eb0b",
   "display_name": "Python 3.7.5 64-bit ('MEG': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Author: Rudi Kreidenhuber, <Rudi.Kreidenhuber@gmail.com>, \n",
    "License: BSD (3-clause)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## To do:\n",
    "\n",
    "Summary statistics (Number of occurences of Semio-Markers, EEG-Markers, ..., EKG?)\n",
    "\n",
    "Figure out how to add plotly figs to mne.Report()\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "----\n",
    "\n",
    "# Video EEG Monitoring Annotation visualizer\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## Inputs:\n",
    " - .edf-files you wish to analyze go into ./data folder\n",
    "\n",
    "## Run:\n",
    " - Press play :-)\n",
    "\n",
    "## Outputs:\n",
    " - Found in results folder\n",
    " - Results for single files are put into a folder that matches the input-filename\n",
    "\n",
    "----\n",
    "\n",
    "## Howto:\n",
    " 1. **Mark Events in EEG file using the following prefixes:**\n",
    " - e- --> EEG marker\n",
    " - s- --> Semiology marker\n",
    " - no prefix --> Everything else (clinical tests during/ after seizure)\n",
    " - i- --> Marker to ignore for focused analysis\n",
    "\n",
    " - One marker **must (!) contain \"Beginn\"** --> this is considered the seizure onset (if it is missing, onset is set to zero)\n",
    " - every marker **can** contain Beginn, for example:\n",
    " - Onset first seen in EEG --> Markername \"e-asdBeginnfgh\" --> would still be recognized as EEG marker and seizure onset\n",
    " 2. **Save EEG file in .edf format and copy to ./data folder**\n",
    " - Every file in this folder is going to be analyzed, if it ends with .edf\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "----\n",
    "## Configuration\n",
    "----\n",
    "\n",
    "### Parameters:\n",
    "graph_sep_line_width\n",
    "- How far blue dashed seperator lines are apart from each other\n",
    "\n",
    "plot_tmin\n",
    "- First time point in seconds from onset, that should be included in the visualization, set to 0 to deactivate\n",
    "\n",
    "plot_tmax\n",
    "- Last time point in seconds from onset, that should be included in the visualization, set to 0 to deactivate\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_name = \"Patient\"\n",
    "graph_sep_line_width = 5\n",
    "plot_tmin = -20\n",
    "plot_tmax = 100"
   ]
  },
  {
   "source": [
    "----\n",
    "## Pipeline start\n",
    "----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "import os\n",
    "import glob\n",
    "import mne\n",
    "from mne import Report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import mpld3\n",
    "import plotly.graph_objects as go\n",
    "from utils import (get_parent_dir, extract_lab_sec, loc_of_sep_lines, plot_seizure_horizontal, plot_seizure_vertical,\n",
    "                                        raw_to_df, extract_groups, extract_ordered_groups, save_plotly_to_html,\n",
    "                                        shrink_df_to_tmax, create_results_folders, save_fig_to_disc, plot_interactive_subplot_with_table,\n",
    "                                        extract_parameters_from_raw, plot_eventcounts)\n",
    "\n",
    "# no need to show figures here\n",
    "plt.ioff() \n",
    "\n",
    "# grab .edfs\n",
    "edfs = glob.glob(\"../data/*.edf\")\n",
    "\n",
    "report = Report(subject=subj_name, title=\"Event summary\")\n",
    "pattern = \"*.edf\"\n",
    "report.parse_folder(\"../data/\", pattern=pattern)"
   ]
  },
  {
   "source": [
    "----\n",
    "## Static visualization\n",
    "----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(edfs) > 0:\n",
    "    # Create folder structure\n",
    "    create_results_folders(edfs)\n",
    "    df = dict() \n",
    "    shrinked_df = dict()\n",
    "    for e in edfs:\n",
    "        print(f\"Now processing file: {e}\")\n",
    "        raw = mne.io.read_raw(e, preload=True)                      #read\n",
    "        df[e], onset = raw_to_df(raw, e)                            # annotations to DataFrame\n",
    "        e_events, s_events, t_events = extract_ordered_groups(df[e], e.split(\"/\")[-1])     # Extract groups\n",
    "\n",
    "        # save\n",
    "        source = e.split(\"/\")[-1].split(\".\")[0]\n",
    "        save_path = (\"../results/\" + source + \"/\" + \"tables/All_events.tsv\")\n",
    "        df[e].to_csv(save_path, sep=\"\\t\")\n",
    "        save_path = (\"../results/\" + source + \"/\" + \"tables/EEG_events.tsv\")\n",
    "        e_events.to_csv(save_path, sep=\"\\t\")\n",
    "        save_path = (\"../results/\" + source + \"/\" + \"tables/Semiology_events.tsv\")\n",
    "        s_events.to_csv(save_path, sep=\"\\t\")\n",
    "        save_path = (\"../results/\" + source + \"/\" + \"tables/Test_events.tsv\")\n",
    "        t_events.to_csv(save_path, sep=\"\\t\")\n",
    "                \n",
    "        # Shrink df to tmax\n",
    "        if df[e].iloc[0,0]:\n",
    "            print(f\"\\nCalculating parameters for focused visualization, tmin = {plot_tmin}, tmax = {plot_tmax} s.\\n\\n\\n\")\n",
    "            \n",
    "            shrinked_df[e] = shrink_df_to_tmax(df=df[e], tmax=plot_tmax, tmin=plot_tmin)\n",
    "            se_events, ss_events, st_events = extract_groups(shrinked_df[e], e)\n",
    "\n",
    "            # Vsualizations\n",
    "            seizure_vertical_w_limits = plot_seizure_vertical(df=shrinked_df[e], eeg=se_events, \n",
    "                                                                semio=ss_events, testing=st_events, \n",
    "                                                                source=e.split(\"/\")[-1], tmin= plot_tmin, \n",
    "                                                                tmax=plot_tmax, name=\"seizure vertical with time limits\",\n",
    "                                                                graph_sep_line_width=graph_sep_line_width)\n",
    "            cap = source + \" --> seizure_vertical_w_limits\"\n",
    "            sec = source + \"-shrinked\"\n",
    "            report.add_figs_to_section(seizure_vertical_w_limits, captions=cap, section=sec)\n",
    "            save_fig_to_disc(seizure_vertical_w_limits, e, cap)\n",
    "\n",
    "            seizure_horizontal_w_limits = plot_seizure_horizontal(df=shrinked_df[e], eeg=se_events, \n",
    "                                                                semio=ss_events, testing=st_events, \n",
    "                                                                source=e.split(\"/\")[-1], tmin= plot_tmin, \n",
    "                                                                tmax=plot_tmax, name=\"seizure horizontal with time limits\",\n",
    "                                                                graph_sep_line_width=graph_sep_line_width)\n",
    "            cap = source + \" --> seizure_horizontal_w_limits\"\n",
    "            sec = source + \"-shrinked\"\n",
    "            report.add_figs_to_section(seizure_horizontal_w_limits, captions=cap, section=sec)\n",
    "            save_fig_to_disc(seizure_horizontal_w_limits, e, \"seizure_horizontal_w_limits\")\n",
    "\n",
    "            event_counts = plot_eventcounts(df=shrinked_df[e], eeg=se_events, semio=ss_events, \n",
    "                                                                source=e.split(\"/\")[-1])\n",
    "            cap = source + \" --> event_conuts_w_limits\"\n",
    "            sec = source + \"-shrinked\"\n",
    "            report.add_figs_to_section(event_counts, captions=cap, section=sec)\n",
    "            save_fig_to_disc(event_counts, e, \"event_conuts_w_limits\")\n",
    "\n",
    "\n",
    "        seizure_vertical = plot_seizure_vertical(df=df[e], eeg=e_events, semio=s_events, \n",
    "                                                    testing=t_events, source=e.split(\"/\")[-1], \n",
    "                                                    name=\"seizure vertical\",\n",
    "                                                    graph_sep_line_width=graph_sep_line_width)\n",
    "        cap = source + \" --> seizure_vertical\"\n",
    "        sec = source\n",
    "        report.add_figs_to_section(seizure_vertical, captions=cap, section=sec)\n",
    "        save_fig_to_disc(seizure_vertical, e, \"seizure_vertical\")\n",
    "\n",
    "        seizure_horizontal = plot_seizure_horizontal(df=df[e], eeg=e_events, semio=s_events, \n",
    "                                                    testing=t_events, source=e.split(\"/\")[-1], \n",
    "                                                    name=\"seizure_horizontal\",\n",
    "                                                    graph_sep_line_width=graph_sep_line_width)\n",
    "        cap = source + \" --> seizure_horizontal\"\n",
    "        sec = source\n",
    "        report.add_figs_to_section(seizure_horizontal, captions=cap, section=sec)\n",
    "        save_fig_to_disc(seizure_horizontal, e, \"seizure_horizontal\")\n",
    "\n",
    "        event_counts = plot_eventcounts(df=df[e], eeg=e_events, semio=s_events, source=e.split(\"/\")[-1])\n",
    "        cap = source + \" --> event_conuts\"\n",
    "        sec = source\n",
    "        report.add_figs_to_section(event_counts, captions=cap, section=sec)\n",
    "        save_fig_to_disc(event_counts, e, \"event_conuts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "----\n",
    "## Save data\n",
    "----"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df_keys = df.keys()\n",
    "# horizontal grand average\n",
    "for idx, val in enumerate(df_keys):\n",
    "    if idx == 0:\n",
    "        concat = df[val]\n",
    "        concat[\"source\"] = val\n",
    "        cols = list(concat)\n",
    "        if not \"source\" in concat:\n",
    "            cols.insert(0, cols.pop(cols.index('source')))\n",
    "        concat = concat.loc[:, cols]\n",
    "        print(concat.time_from_onset)\n",
    "        concat = concat.sort_values(by=[\"time_from_onset\"])\n",
    "        concat = concat.drop(columns=[\"onset\"], axis=1)\n",
    "        concat[\"order_of_occurence\"] = (1 + np.arange(len(concat.loc[:,\"time_from_onset\"])))\n",
    "        \n",
    "    if idx > 0:\n",
    "        new_df = df[val]\n",
    "        if not \"source\" in new_df.keys():\n",
    "            new_df[\"source\"] = val\n",
    "        cols = list(new_df)\n",
    "        cols.insert(0, cols.pop(cols.index('source')))\n",
    "        new_df = new_df.loc[:, cols]\n",
    "        new_df.drop(columns=[\"onset\"], axis=1, inplace=True)\n",
    "        new_df[\"order_of_occurence\"] = (1 + np.arange(len(new_df.loc[:,\"time_from_onset\"]))).astype(int)\n",
    "        concat = pd.merge(concat, new_df, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "    #print(f\"\\n\\n\\n\\nRun {idx} --> concat = {concat}\")\n",
    "    idx += 1\n",
    "\n",
    "concat.to_csv(\"../results/grand_average//tables/All_Data_horizontal.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# EEG/Semio/Test horizontal grand_average\n",
    "for idx, val in enumerate(df_keys):\n",
    "    if idx == 0:\n",
    "        eeg_ga, semio_ga, test_ga = extract_ordered_groups(df[val], source = val)\n",
    "        # this should not be necessary:\n",
    "        eeg_ga.sort_values(by=[\"time_from_onset\"])\n",
    "        semio_ga.sort_values(by=[\"time_from_onset\"])\n",
    "        test_ga.sort_values(by=[\"time_from_onset\"])\n",
    "        \n",
    "    if idx > 0:\n",
    "        new_df = df[val]\n",
    "        ne, ns, nt = extract_ordered_groups(new_df, source = val)\n",
    "        #new_df.insert(loc=0, column='source', value=val.split(\"/\")[-1])\n",
    "        eeg_ga = pd.merge(eeg_ga, ne, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \")) \n",
    "        semio_ga = pd.merge(semio_ga, ns, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "        test_ga = pd.merge(test_ga, nt, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "    idx += 1\n",
    "\n",
    "eeg_ga.drop(columns=[\"onset\"], axis=1)\n",
    "semio_ga.drop(columns=[\"onset\"], axis=1)\n",
    "test_ga.drop(columns=[\"onset\"], axis=1)\n",
    "\n",
    "eeg_ga = eeg_ga.sort_values(by=[\"time_from_onset\"])\n",
    "semio_ga = semio_ga.sort_values(by=[\"time_from_onset\"])\n",
    "test_ga = test_ga.sort_values(by=[\"time_from_onset\"])\n",
    "\n",
    "eeg_ga.to_csv(\"../results/grand_average//tables/EEE_grand_average.tsv\", sep=\"\\t\")\n",
    "semio_ga.to_csv(\"../results/grand_average//tables/Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "test_ga.to_csv(\"../results/grand_average//tables/Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Vertical grand average\n",
    "for idx, val in enumerate(df_keys):\n",
    "    if idx == 0:\n",
    "        concat = df[val]\n",
    "        concat.loc[:, \"source\"] = val.split(\"/\")[-1]        \n",
    "    if idx > 0:\n",
    "        new_df = df[val]\n",
    "        new_df.loc[:, \"source\"] = val.split(\"/\")[-1]\n",
    "        concat = pd.concat([concat, new_df], axis=0)     \n",
    "    idx += 1\n",
    "concat.drop(columns=[\"onset\"], axis=1)\n",
    "concat.drop(index=4, axis=1, inplace=True)\n",
    "\n",
    "concat = concat.sort_values(by=[\"time_from_onset\"])\n",
    "concat.to_csv(\"../results/grand_average/tables/All_events.tsv\", sep=\"\\t\")"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "----\n",
    "# Interactive Visualization\n",
    "----"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seizure subplots\n",
    "event_folders = glob.glob(\"../results/*\")\n",
    "data = dict()\n",
    "interactive_plots = dict()\n",
    "for e in event_folders:\n",
    "    source = e.split(\"/\")[-1]\n",
    "    tsv = e + \"/tables/All_events.tsv\"\n",
    "    data[source] = pd.read_csv(tsv, sep=\"\\t\")\n",
    "    EEG, Semio, Test = extract_ordered_groups(data[source], source)\n",
    "    interactive_plots[source] = plot_interactive_subplot_with_table(data[source], EEG, Semio, Test, title=source)\n",
    "    save_plotly_to_html(interactive_plots[source], source=source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"grand_average\"\n",
    "html = \"/Users/idrael/git/VEEG_Event_Processor/results/grand_average/viz/grand_average_interactive_viz.html\"\n",
    "report.add_htmls_to_section(html, section=\"test\", captions=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = interactive_plots[\"grand_average\"]\n",
    "html = mpld3.fig_to_html(fig)\n",
    "report.add_figs_to_section(html, section=\"test\", captions=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_save_name = \"../results/cumulative_report.html\"\n",
    "report.save(report_save_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}