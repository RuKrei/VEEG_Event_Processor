{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Rudi Kreidenhuber, <Rudi.Kreidenhuber@gmail.com>, \n",
    "License: BSD (3-clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Video EEG Monitoring Annotation visualizer\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## Inputs:\n",
    " - .edf-files you wish to analyze go into ./data folder\n",
    "\n",
    "## Run:\n",
    " - In the menu bar click Cell --> Run all\n",
    " - Press play :-)\n",
    "\n",
    "## Outputs:\n",
    " - Found in results folder\n",
    " - Results for single files are put into a folder that matches the input-filename\n",
    "\n",
    "----\n",
    "\n",
    "## Howto:\n",
    " 1. **Mark Events in EEG file using the following prefixes:**\n",
    " - e- --> EEG marker\n",
    " - s- --> Semiology marker\n",
    " - no prefix --> Everything else (clinical tests during/ after seizure)\n",
    " - i- --> Marker to ignore for analysis\n",
    "\n",
    " - One marker **must (!) contain \"Beginn\"** --> this is considered the seizure onset (if it is missing, onset is set to zero)\n",
    " - every marker **can** contain Beginn, for example:\n",
    " - Onset first seen in EEG --> Markername \"e-asdBeginnfgh\" --> would still be recognized as EEG marker and seizure onset\n",
    " 2. **Save EEG file in .edf format and copy to ./data folder**\n",
    " - Every file in this folder is going to be analyzed, if it ends with .edf\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# general imports\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import mne\n",
    "import re\n",
    "from mne import Report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "from shutil import copyfile\n",
    "\n",
    "# plotly imports\n",
    "import plotly as py\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "win = True if platform.system().lower().startswith(\"win\") else False\n",
    "folder_splitter = \"\\\\\" if win else \"/\"\n",
    "CONFIG_FILE = \"..\\data\\VEEG_config.xlsx\"\n",
    "if not os.path.isfile(CONFIG_FILE):\n",
    "    raise Exception(\"No VEEG_config.xlsx - file found\")\n",
    "print(\"Using configuration file: \", CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Helper functions\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_edfs(directory=None) -> list:\n",
    "    pwd = os.getcwd()\n",
    "    dir = os.path.join(pwd, directory, \"*.edf\")\n",
    "    return glob.glob(dir)\n",
    "\n",
    "def grab_subject_name() -> str:\n",
    "    return os.getcwd().split(folder_splitter)[-2].split(\"VEEG_Event_Processor-\")[-1]\n",
    "\n",
    "def extract_lab_sec(df):\n",
    "    times = df[\"time_from_onset\"]\n",
    "    labels = df[\"description\"]\n",
    "    return times, labels\n",
    "\n",
    "def extract_ordered_groups(df=None):\n",
    "    #df = df.drop_duplicates(subset=[\"description\"], keep=\"first\")   # not doing this, as e- and s- events might reuccur!\n",
    "    e_events = df[df[\"description\"].str.startswith(\"e-\")]\n",
    "    e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
    "    s_events = df[df[\"description\"].str.startswith(\"s-\")]\n",
    "    s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
    "    t_events = df[~df[\"description\"].str.startswith(\"s-\")]\n",
    "    t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
    "    t_events[\"order_of_occurence\"] = (np.arange(len(t_events.axes[0])) +1).astype(int)\n",
    "    return e_events, s_events, t_events\n",
    "\n",
    "def write_excel_table(e_events=None, s_events=None, win=False):\n",
    "    xlsx_file = \"All_data_grand_average.xlsx\"\n",
    "    xlsx_file = os.path.join(\"..\", \"results\", xlsx_file)\n",
    "    writer = pd.ExcelWriter (xlsx_file)\n",
    "    # EEG-Events\n",
    "    i = 1\n",
    "    left = [\"EEG\", \"\", \"File:\", \"Pattern 1:\", \"Pattern 2:\", \"Pattern 3:\", \"Pattern 4:\", \n",
    "                \"Pattern 5:\", \"Pattern 6:\", \"Pattern 7:\",\n",
    "                \"Pattern 8:\", \"Pattern 9:\", \"Pattern 10:\", \"...\"]\n",
    "    for e in e_events.keys():\n",
    "        try:\n",
    "            if e_events[e].empty:\n",
    "                print(f\"Empty EEG-List --> {e_events[e]}, omitting\")\n",
    "            else:\n",
    "                df_e = pd.DataFrame(e_events[e], columns=[\"description\"])\n",
    "                _, file = os.path.split(e)\n",
    "                df_e = df_e.rename(columns={\"description\": file.split(\".edf\")[0]})\n",
    "                df_e.to_excel(writer, sheet_name=\"EEG_1\", startcol=(i+1), startrow=2, header=True, index=False)\n",
    "                i += 1\n",
    "            left_df = pd.DataFrame(left)\n",
    "            left_df.to_excel(writer, sheet_name=\"EEG_1\", startcol=0, startrow=0, header=False, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Excel-File: Something went wrong trying to parse EEG-Events for {e}\")\n",
    "    # Semiology-Events - list\n",
    "    sem_left = [\"Semiology\", \"\", \"File:\", \"Pattern 1:\", \"Pattern 2:\", \"Pattern 3:\", \"Pattern 4:\", \n",
    "                \"Pattern 5:\", \"Pattern 6:\", \"Pattern 7:\",\n",
    "                \"Pattern 8:\", \"Pattern 9:\", \"Pattern 10:\", \"...\"]\n",
    "    i = 1\n",
    "    for s in s_events.keys():\n",
    "        try:\n",
    "            if s_events[s].empty:\n",
    "                print(f\"Empty Semiology-List --> {s_events[s]}, omitting\")\n",
    "            else:\n",
    "                df_s = pd.DataFrame(s_events[s], columns=[\"description\"])\n",
    "                _, file = os.path.split(s)\n",
    "                df_s = df_s.rename(columns={\"description\": file.split(\".edf\")[0]})\n",
    "                df_s.to_excel(writer, sheet_name=\"Semiology_1\", startcol=(i+1), startrow=2, header=True, index=False)\n",
    "                #writer.save()\n",
    "                i += 1\n",
    "            sem_left_df = pd.DataFrame(sem_left)\n",
    "            sem_left_df.to_excel(writer, sheet_name=\"Semiology_1\", startcol=0, startrow=0, header=False, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Excel-File: Something went wrong trying to parse Semiology-Events for {s}\")\n",
    "    # Semiology events - pattern = index\n",
    "    for s in s_events.keys():\n",
    "        _, file = os.path.split(s)\n",
    "        try:\n",
    "            if s_events[s].empty:\n",
    "                print(f\"Empty Semiology-List --> {s_events[s]}, omitting\")\n",
    "            else:\n",
    "                try:\n",
    "                    # merge 2 dataframes\n",
    "                    new_df = pd.DataFrame(s_events[s], columns=[\"description\", \"order_of_occurence\"])\n",
    "                    new_df = new_df.rename(columns={\"order_of_occurence\": file.split(\".edf\")[0]})\n",
    "                    df_s = pd.merge(df_s, new_df, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "                except Exception as e:\n",
    "                    # there is no dataframe to start with, so create one\n",
    "                    print(e)\n",
    "                    df_s = pd.DataFrame(s_events[s], columns=[\"description\", \"order_of_occurence\"])\n",
    "                    df_s = df_s.rename(columns={\"order_of_occurence\": file.split(\".edf\")[0]})\n",
    "                # write to file\n",
    "                df_s.to_excel(writer, sheet_name=\"Semiology_2\", startcol=1, startrow=3, header=True, index=False)\n",
    "            sem_left = [\"Semiology\", \"\"]\n",
    "            sem_left_df = pd.DataFrame(sem_left)\n",
    "            sem_left_df.to_excel(writer, sheet_name=\"Semiology_2\", startcol=0, startrow=0, header=False, index=False)\n",
    "            writer.save()\n",
    "        except Exception as e:\n",
    "            print(f\"Excel-File: Something went wrong trying to parse Semiology-Events for {s}:\")\n",
    "            print(e)\n",
    "            \n",
    "def create_results_folders(edfs=None):\n",
    "    for e in edfs:\n",
    "        name = e.split(folder_splitter)[-1].split(\".\")[0]\n",
    "        directory = os.path.join(\"..\", \"results\", name)\n",
    "        viz = os.path.join(directory, \"viz\")\n",
    "        tables = os.path.join(directory, \"tables\")\n",
    "        for d in [directory, viz, tables]:\n",
    "            if not os.path.exists(d):\n",
    "                os.makedirs(d, exist_ok=True)\n",
    "        if len(edfs) > 1:\n",
    "            d = os.path.join(\"..\", \"results\", \"grand_average\", \"tables\")\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "            d = os.path.join(\"..\", \"results\", \"grand_average\", \"viz\")\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "            \n",
    "def plot_interactive_subplot_with_table(df=None, eeg=None, semio=None, testing=None, title=None):\n",
    "    xaxis_title=\"Time in seconds (from seizure onset)\"\n",
    "    fig = make_subplots(rows=5, cols=1, shared_xaxes=\"all\", \n",
    "                        specs=[[{\"type\": \"table\"}],\n",
    "                                [{\"type\": \"scatter\"}],\n",
    "                                [{\"type\": \"scatter\"}],\n",
    "                                [{\"type\": \"scatter\"}],\n",
    "                                [{\"type\": \"scatter\"}]],\n",
    "                        subplot_titles=(\"Events\", \"EEG\", \"Semiology\", \"Testing\", \"All events\"),\n",
    "                        row_width=[0.1, 0.1, 0.1, 0.1, 0.8])\n",
    "    # Add traces\n",
    "    # data\n",
    "    fig.add_trace(go.Table(\n",
    "                        header=dict(\n",
    "                                values=df.columns[2:], font=dict(size=10)),\n",
    "                        cells=dict(\n",
    "                            values=[df[i].tolist() for i in df.columns[2:]],\n",
    "                            align=\"left\")\n",
    "                        ),\n",
    "                        row=1, col=1)\n",
    "    # scatter plots\n",
    "    x_axis = df[\"time_from_onset\"]\n",
    "    y_axis = np.ones_like(x_axis)\n",
    "    # eeg\n",
    "    times, labels = extract_lab_sec(eeg)\n",
    "    fig.add_trace(go.Scatter(x=times, y=y_axis,\n",
    "                        mode='markers',                 #mode=\"markers+text\"\n",
    "                        hoverinfo=\"name+x+text\",\n",
    "                        name='EEG',\n",
    "                        text=labels,\n",
    "                        marker_symbol=\"diamond\"), row=2, col=1)\n",
    "    # semio\n",
    "    times, labels = extract_lab_sec(semio)\n",
    "    fig.add_trace(go.Scatter(x=times, y=y_axis,\n",
    "                        mode='markers',\n",
    "                        name='Semiology',\n",
    "                        text=labels,\n",
    "                        marker_symbol=\"x\"), row=3, col=1)\n",
    "    # testing\n",
    "    times, labels = extract_lab_sec(testing)\n",
    "    fig.add_trace(go.Scatter(x=times, y=y_axis,\n",
    "                        mode='markers',\n",
    "                        name='Testing',\n",
    "                        text=labels,\n",
    "                        marker_symbol=\"circle\"), row=4, col=1)\n",
    "    # grand average\n",
    "    times, labels = extract_lab_sec(df)\n",
    "    fig.add_trace(go.Scatter(x=times, y=y_axis,\n",
    "                        mode='markers',\n",
    "                        name='All events',\n",
    "                        text=labels,\n",
    "                        marker_symbol=\"hexagon2-open-dot\"), row=5, col=1)\n",
    "    fig.update_layout(title=title, yaxis_title=\"\")\n",
    "    fig.update_xaxes(rangeslider={\"visible\":True}, title={\"text\":xaxis_title}, row=5)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    fig.update_layout(width=1500, height=1200)\n",
    "    return fig\n",
    "\n",
    "def save_plotly_to_html(fig=None, source=None):\n",
    "    save_dir = os.path.join(\"..\", \"results\", source, \"viz\")\n",
    "    save_name = os.path.join(save_dir, (source + \"_interactive_viz.html\"))\n",
    "    fig.write_html(save_name)\n",
    "\n",
    "def plot_interactive_eeg_and_semio(eeg=None, semio=None, source=None):\n",
    "    fig = make_subplots(rows=1, cols=2, start_cell=\"top-left\",\n",
    "                        subplot_titles=(\"EEG events\", \"Semiology events\"),\n",
    "                        #row_width=[0.1, 0.1, 0.1],\n",
    "                        horizontal_spacing=0.2\n",
    "                        )\n",
    "    # EEG\n",
    "    fig.add_trace(go.Histogram(y=eeg[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"EEG\"),\n",
    "                    row=1, col=1\n",
    "                    )\n",
    "    # Semio\n",
    "    fig.add_trace(go.Histogram(y=semio[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"Semiology\"),\n",
    "                    row=1, col=2\n",
    "                    )    \n",
    "    fig.update_yaxes(categoryorder=\"total descending\")\n",
    "    fig.update_layout(width=1100, height=800, title=source,\n",
    "                        xaxis_title=\"Number of occurences\",\n",
    "                        yaxis_title=\"\")\n",
    "    return fig\n",
    "\n",
    "def plot_interactive_testing_results(t_events=None, title=\"Testing results\"):\n",
    "    t_events_failed = t_events[t_events[\"description\"].apply(lambda x: x.endswith(\"0\"))]\n",
    "    t_events_failed[\"description\"] = t_events_failed.description.str.split(\"0\").str[0]\n",
    "    t_events_passed = t_events[t_events[\"description\"].apply(lambda x: x.endswith(\"1\"))]\n",
    "    t_events_passed[\"description\"] = t_events_passed.description.str.split(\"1\").str[0]\n",
    "    fig = go.Figure()\n",
    "    # passed\n",
    "    fig.add_trace(go.Scatter(x=t_events_passed[\"time_from_onset\"], \n",
    "                        y=t_events_passed[\"description\"],\n",
    "                        name=\"passed\",\n",
    "                        mode=\"markers\",\n",
    "                        hovertext=t_events_passed[\"source\"])\n",
    "                    )\n",
    "    # failed\n",
    "    fig.add_trace(go.Scatter(x=t_events_failed[\"time_from_onset\"], \n",
    "                        y=t_events_failed[\"description\"],\n",
    "                        name=\"failed\",\n",
    "                        mode=\"markers\",\n",
    "                        hovertext=t_events_passed[\"source\"])\n",
    "                    )  \n",
    "    fig.update_layout(width=1100, height=800, title=title,\n",
    "                    xaxis_title=\"Time in seconds from onset\",\n",
    "                    yaxis_title=\"\")\n",
    "    fig.update_yaxes(categoryorder=\"category ascending\")\n",
    "    return fig\n",
    "\n",
    "def plot_interactive_EEG_results(e_events=None, title=\"EEG results\"):\n",
    "    fig = px.scatter(e_events, y=e_events[\"description\"], x=e_events[\"time_from_onset\"],\n",
    "                        color=e_events[\"source\"])\n",
    "    fig.update_layout(width=1100, height=800, title=title, xaxis_title=\"Time in seconds from onset\")\n",
    "    return fig\n",
    "\n",
    "def plot_interactive_semio_results(s_events=None, title=\"Semiology results\"):\n",
    "    fig = px.scatter(s_events, y=s_events[\"description\"], x=s_events[\"time_from_onset\"],\n",
    "                        color=s_events[\"source\"])\n",
    "    fig.update_layout(width=1100, height=800, title=title, xaxis_title=\"Time in seconds from onset\")\n",
    "    return fig\n",
    "\n",
    "def make_grand_average_report(df, name=\"grand_average\", subj_name=None):\n",
    "    ga_report_title = subj_name + \" - All seizures\"\n",
    "    ga_report = Report(subject=subj_name, title=ga_report_title)\n",
    "    EEG = dict()       # EEG events\n",
    "    Semio = dict()       # Semiology events\n",
    "    Test = dict()       # Testing events\n",
    "    EEG[name], Semio[name], Test[name] = extract_ordered_groups(df=df)\n",
    "    # grand_average figure\n",
    "    ga_fig = plot_interactive_subplot_with_table(df=df, eeg=EEG[name], \n",
    "                                                semio=Semio[name], testing=Test[name], title=ga_report_title)\n",
    "    cap = name + \" VIZ --> All seizures\"\n",
    "    ga_report.add_htmls_to_section(ga_fig.to_html(full_html=False), \n",
    "                                section=name, captions=cap)\n",
    "    # EEG\n",
    "    cap = name + \" VIZ --> All EEG results\"\n",
    "    eeg_viz = plot_interactive_EEG_results(e_events=EEG[name], title=cap)\n",
    "    ga_report.add_htmls_to_section(eeg_viz.to_html(full_html=False), section=name, captions=cap)\n",
    "    # Testing\n",
    "    if name == \"grand_average\":          # Testing-Markers are not renamed, no point in visualizing them twice\n",
    "        cap = name + \" VIZ --> All Testing results\"\n",
    "        testing_viz = plot_interactive_testing_results(t_events=Test[name], title=cap)\n",
    "        ga_report.add_htmls_to_section(testing_viz.to_html(full_html=False), section=name, captions=cap)\n",
    "    # Semiology\n",
    "    cap = name + \" VIZ --> All Semiology results\"\n",
    "    semio_viz = plot_interactive_semio_results(s_events=Semio[name], title=cap)\n",
    "    ga_report.add_htmls_to_section(semio_viz.to_html(full_html=False), section=name, captions=cap)\n",
    "    return ga_report\n",
    "\n",
    "\"\"\"\n",
    "def extract_parameters_from_raw(raw=None):\n",
    "    highp = raw.info[\"highpass\"]\n",
    "    lowp = raw.info[\"lowpass\"]\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    aq = raw.info[\"meas_date\"]\n",
    "    channels = raw.info[\"ch_names\"]\n",
    "    nr_channels = raw.info[\"nchan\"]\n",
    "    return highp, lowp, sfreq, aq, channels, nr_channels\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _return_raw(edf=None):\n",
    "    return mne.io.read_raw(edf, preload = True)\n",
    "\n",
    "def _set_beginning(df):\n",
    "    e_beginning = df[['e-beginn' in x for x in df['description'].str.lower()]]\n",
    "    s_beginning = df[['s-beginn' in x for x in df['description'].str.lower()]]\n",
    "    the_beginning = pd.concat([e_beginning, s_beginning], axis=0)\n",
    "    if the_beginning.empty:\n",
    "        print(f\"Error: No marker containing \\\"Beginn\\\" found, cannot determine seizure onset for: {df}\")\n",
    "        print(\"Setting seizure onset to the beginning of the file\")\n",
    "        onset = \"No seizure onset was marked\"\n",
    "        df.loc[-1] = [0, \"_Beginn_(assumed)_\"]\n",
    "        df.index = df.index + 1\n",
    "        df = df.sort_index()\n",
    "        the_beginning.loc[1,:] = [0, \"_Beginn-(assumed)_\"]  \n",
    "    samp_beginn = the_beginning.iloc[0,0].astype(float)\n",
    "    onset = samp_beginn.astype(float)\n",
    "    time_from_onset = df[\"onset\"]\n",
    "    time_from_onset = time_from_onset  - samp_beginn\n",
    "    df[\"time_from_onset\"] = time_from_onset\n",
    "    return (df.drop([\"onset\"], axis = 1), onset)\n",
    "\n",
    "def _add_source_column(df, source=None):\n",
    "    # Add source column to the left\n",
    "    df[\"source\"] = source.split(folder_splitter)[-1].split(\".edf\")[0]\n",
    "    cols = list(df)\n",
    "    cols.insert(0, cols.pop(cols.index('source')))\n",
    "    return df.loc[:, cols], df[\"source\"][0]\n",
    "\n",
    "def _read_config_file(config_file=CONFIG_FILE):\n",
    "    mEEG = pd.read_excel(config_file, sheet_name=\"EEG\")\n",
    "    mEEG = mEEG[[\"mName\", \"mTranslation\", \"mSubstitution\"]]\n",
    "    mEEG.dropna(how=\"all\", inplace=True)\n",
    "    mEEG = mEEG.set_index(\"mName\")\n",
    "    mSemio = pd.read_excel(config_file, sheet_name=\"Semio\")\n",
    "    mSemio = mSemio[[\"mName\", \"mTranslation\", \"mSubstitution\"]]\n",
    "    mSemio.dropna(how=\"all\", inplace=True)\n",
    "    mSemio = mSemio.set_index(\"mName\")\n",
    "    mModifiers = pd.read_excel(config_file, sheet_name=\"Modifiers\")\n",
    "    mModifiers = mModifiers[[\"mName\", \"mTranslation\", \"mSubstitution\"]]\n",
    "    mModifiers.dropna(how=\"all\", inplace=True)\n",
    "    mModifiers = mModifiers.set_index(\"mName\")\n",
    "    mAnatomy = pd.read_excel(config_file, sheet_name=\"Anatomy\")\n",
    "    mAnatomy = mAnatomy[[\"mName\", \"mTranslation\", \"mSubstitution\"]]\n",
    "    mAnatomy.dropna(how=\"all\", inplace=True)\n",
    "    mAnatomy = mAnatomy.set_index(\"mName\")\n",
    "    return(mEEG, mSemio, mModifiers, mAnatomy)\n",
    "\n",
    "def _marker_to_text(string=None, substitute=True):\n",
    "    \"\"\"\n",
    "    Splits the input string as needed\n",
    "    Translates according to CONFIG_FILE\n",
    "    returns:\n",
    "      a string in human readable format\n",
    "      type: EEG, Semio, Testing\n",
    "      markers_code: e-\"IAmTheBaseName\"\n",
    "    \"\"\"\n",
    "    mEEG, mSemio, mModifiers, mAnatomy = _read_config_file(config_file=CONFIG_FILE)\n",
    "    d = dict()\n",
    "    readbable = str()\n",
    "    # ignore the i- markers - not need to translate those\n",
    "    if string.startswith(\"i-\"):\n",
    "        return \"ignored\"\n",
    "    # the rest belongs to one of three groups\n",
    "    elif string.startswith(\"e-\"):\n",
    "        d[\"type\"] = \"EEG\"\n",
    "    elif string.startswith(\"s-\"):\n",
    "        d[\"type\"] = \"Semiology\"\n",
    "    else:\n",
    "        d[\"type\"] = \"Testing\"\n",
    "\n",
    "    # this returns a list of markers and modifiers\n",
    "    rex = re.findall(r\"[-|+]\\w*\", string)\n",
    "    # First job is to define the base \n",
    "    try:\n",
    "        # base comes first\n",
    "        r = rex[0].strip(\"-\")\n",
    "        rr = rex[0]\n",
    "        if r in mEEG.index:\n",
    "            base = mEEG.loc[str(r)][0]\n",
    "        else:\n",
    "            base = str(r)\n",
    "        # now we can drop it from the list\n",
    "        rex.remove(rr)\n",
    "    # This might not be a smart move :-(\n",
    "    except Exception as e:\n",
    "        print(f\"Could not determine base: {e}, setting it to {string}\")\n",
    "        base = string\n",
    "\n",
    "\n",
    "    # 2nd job: substitutions\n",
    "    if substitute == True:\n",
    "        for r in rex:\n",
    "            r = r.split(\"-\")[-1].split(\"+\")[-1] \n",
    "            if r in mEEG.index:\n",
    "                if mEEG.loc[str(r)][1] != None:\n",
    "                    newitems = list()\n",
    "                    try:\n",
    "                        print(f\"mEEG.loc[str(r)][1] --> {mEEG.loc[str(r)][1]}\")\n",
    "                        # split the substitution\n",
    "                        subst = str(mEEG.loc[str(r)][1]).split(\"-\")\n",
    "                        for s in subst:\n",
    "                            if not s in rex:\n",
    "                                newitems.append(s)\n",
    "                        for n in newitems:\n",
    "                            rex.append(str(\"-\" + n))    \n",
    "                        # delete r, as it has just been substituted\n",
    "                        rex.remove(str(\"-\" + r))\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "            if r in mSemio.index:\n",
    "                pass\n",
    "            if r in mModifiers.index:\n",
    "                pass\n",
    "            if r in mAnatomy.index:\n",
    "                pass\n",
    "    print(f\"rex after substitution   -->   {rex}\")      \n",
    " #   define placeholder lists\n",
    "    strEEG = []\n",
    "    strSemio = []\n",
    "    strAna = []\n",
    "    strMod = []\n",
    "    strNotRecognized = []\n",
    "\n",
    "    # now we can go throug the modifiers etc.\n",
    "    for r in rex:\n",
    "        r = r.split(\"-\")[-1] \n",
    "        r = r.split(\"+\")[-1]\n",
    "        r = r.strip(\"-\")     \n",
    "        if r in mEEG.index:\n",
    "            strEEG.append(mEEG.loc[str(r)][0])\n",
    "        elif r in mSemio.index:\n",
    "            strSemio.append(mSemio.loc[str(r)][0])\n",
    "        elif str(\"+\" + r) in mModifiers.index:\n",
    "            strMod.append(str(mModifiers.loc[str(\"+\" + r)][0]))\n",
    "        elif str(r) in mModifiers.index:\n",
    "            strMod.append(str(\"with \" + mModifiers.loc[str(r)][0]))\n",
    "        elif r in mAnatomy.index:\n",
    "            strAna.append(mAnatomy.loc[str(r)][0])\n",
    "        else:\n",
    "            strNotRecognized.append(r)\n",
    "    # make sure output order is always the same + return \n",
    "    readable = \"\"\n",
    "    if strEEG is not []:\n",
    "        #strEEG = set(strEEG)\n",
    "        for e in sorted(strEEG):\n",
    "            readable += str(\" \" + e)\n",
    "    if strSemio is not []:\n",
    "        for m in sorted(strSemio):\n",
    "            readable += str(\" \" + m)\n",
    "    if strMod is not []:\n",
    "        for m in sorted(strMod):\n",
    "            readable += str(\" \" + m)\n",
    "    if strAna is not []:\n",
    "        for a in sorted(strAna):\n",
    "            readable += str(\" \" + a)     \n",
    "    if strNotRecognized is not []:\n",
    "        for m in sorted(strNotRecognized):\n",
    "            readable += str(\" \" + m)\n",
    "    # bring back the prefix\n",
    "    if string.startswith(\"e-\"):\n",
    "        prefix = \"e-\"\n",
    "    elif string.startswith(\"s-\"):\n",
    "        prefix = \"s-\"\n",
    "    else:\n",
    "        prefix = \"\"\n",
    "    readable = prefix + base + \" \" + readable\n",
    "    if readable.startswith(\" \"):\n",
    "        readable.lstrip(\" \")\n",
    "    return readable\n",
    "\n",
    "def raw_to_df(f):\n",
    "    raw = _return_raw(f)\n",
    "    df = pd.DataFrame(raw.annotations)\n",
    "    df = df.drop([\"duration\"], axis=1)\n",
    "    df = df.drop([\"orig_time\"], axis=1)\n",
    "    df, onset = _set_beginning(df)\n",
    "    df, source = _add_source_column(df, source=f)\n",
    "    return df, onset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Main function\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os.getcwd().endswith(\"src\"): \n",
    "        os.chdir(os.path.join(\".\", folder_splitter, \"src\"))\n",
    "        print(f\"Changed working directory to {os.getcwd()}\")\n",
    "\n",
    "    edfs = grab_edfs(\"..\\\\data\")\n",
    "    subj_name = grab_subject_name()\n",
    "    create_results_folders(edfs)\n",
    "    print(f\"Subject/ Patient name is: {subj_name}\")\n",
    "    print(f\"Found the following edfs:\\n {edfs}\\n\\n\")\n",
    "    \n",
    "    df = dict()             # all data\n",
    "    e_events = dict()       # EEG events\n",
    "    s_events = dict()       # Semiology events\n",
    "    t_events = dict()       # Testing events\n",
    "    \n",
    "    for e in edfs:\n",
    "        print(f\"Now processing file: {e}\")        \n",
    "        df[e], onset = raw_to_df(e)\n",
    "        e_events[e], s_events[e], t_events[e] = extract_ordered_groups(df[e])\n",
    "    #save\n",
    "        csv_path = os.path.join(\"..\", \"results\", e.split(folder_splitter)[-1].split(\".\")[0], \"tables\")\n",
    "        e_file = e.split(folder_splitter)[-1].split(\".\")[0]\n",
    "        tsv_name = \"All_data_\" + e_file + \".tsv\"\n",
    "        fname = os.path.join(csv_path, tsv_name)\n",
    "        df[e].to_csv(fname, sep=\"\\t\")\n",
    "        tsv_name = \"EEG_data_\" + e_file + \".tsv\"\n",
    "        fname = os.path.join(csv_path, tsv_name)\n",
    "        e_events[e].to_csv(fname, sep=\"\\t\")\n",
    "        tsv_name = \"Semiology_data_\" + e_file + \".tsv\"\n",
    "        fname = os.path.join(csv_path, tsv_name)\n",
    "        s_events[e].to_csv(fname, sep=\"\\t\")\n",
    "        tsv_name = \"Testing_data_\" + e_file + \".tsv\"\n",
    "        fname = os.path.join(csv_path, tsv_name)\n",
    "        t_events[e].to_csv(fname, sep=\"\\t\")    \n",
    "\n",
    "    for idx, val in enumerate(df.keys()):\n",
    "        if idx == 0:\n",
    "            # all data vertical\n",
    "            vconcat = df[val]\n",
    "            # all data horizontal\n",
    "            concat = df[val]\n",
    "            source = \"source_\" + str(idx)\n",
    "            concat[source] = val\n",
    "            cols = list(concat)\n",
    "            cols.insert(0, cols.pop(cols.index(source)))\n",
    "            concat = concat.loc[:, cols]\n",
    "            concat = concat.sort_values(by=[\"time_from_onset\"])\n",
    "            if \"source\" in concat.keys():\n",
    "                concat.drop(columns=[\"source\"], axis=1, inplace=True)\n",
    "            concat[\"order_of_occurence\"] = (1 + np.arange(len(concat.loc[:,\"time_from_onset\"])))\n",
    "            # eeg, semio\n",
    "            eeg_ga, semio_ga, test_ga = e_events[val], s_events[val], t_events[val]  # should be same keys as for e in edfs...\n",
    "        if idx > 0:\n",
    "            # all data vertical\n",
    "            vnew_df = df[val]\n",
    "            vconcat = pd.concat([vconcat, vnew_df], axis=0)\n",
    "            # all data horizontal\n",
    "            new_df = df[val]\n",
    "            source = \"source_\" + str(idx)\n",
    "            new_df[source] = val\n",
    "            cols = list(new_df)\n",
    "            cols.insert(0, cols.pop(cols.index(source)))\n",
    "            new_df = new_df.loc[:, cols]\n",
    "            if \"source\" in new_df.keys():\n",
    "                new_df.drop(columns=[\"source\"], axis=1, inplace=True)\n",
    "            new_df[\"order_of_occurence\"] = (1 + np.arange(len(new_df.loc[:,\"time_from_onset\"]))).astype(int)\n",
    "            concat = pd.merge(concat, new_df, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "            # eeg, semio\n",
    "            ne, ns, nt = e_events[val], s_events[val], t_events[val]\n",
    "            eeg_ga = pd.merge(eeg_ga, ne, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \")) \n",
    "            semio_ga = pd.merge(semio_ga, ns, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "            test_ga = pd.merge(test_ga, nt, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "        idx += 1\n",
    "    if \"source_0\" in vconcat.keys():\n",
    "        vconcat.drop(columns=[\"source_0\"], axis=1, inplace=True)\n",
    "    # save grand averages\n",
    "    base_dir = os.path.join (\"..\", \"results\", \"grand_average\", \"tables\")\n",
    "    eeg_ga.to_csv(os.path.join(base_dir, \"EEG_data_grand_average.tsv\"), sep=\"\\t\")\n",
    "    semio_ga.to_csv(os.path.join(base_dir, \"Semiology_data_grand_average.tsv\"), sep=\"\\t\")\n",
    "    test_ga.to_csv(os.path.join(base_dir, \"Testing_data_grand_average.tsv\"), sep=\"\\t\")\n",
    "    concat.to_csv(os.path.join(base_dir, \"All_data_grand_average_horizontal.tsv\"), sep=\"\\t\")\n",
    "    vconcat.to_csv(os.path.join(base_dir, \"All_data_grand_average.tsv\"), sep=\"\\t\")\n",
    "    # write excel file\n",
    "    write_excel_table(e_events, s_events, win=win) \n",
    "    # Plots/report for single seizures\n",
    "    report_title = subj_name + \" - Single seizure plots\"\n",
    "    report = Report(subject=subj_name, title=report_title)\n",
    "    event_search = os.path.join(\"..\", \"results\", \"*\")\n",
    "    event_folders = glob.glob(event_search)\n",
    "    data = dict()\n",
    "    EEG = dict()\n",
    "    Semio = dict()\n",
    "    Test = dict()\n",
    "    interactive_plots = dict()\n",
    "    for e in event_folders:\n",
    "        if not os.path.isdir(e):\n",
    "            print(f\"Omitting: {e}\")\n",
    "        else:\n",
    "            source = e.split(folder_splitter)[-1].split(\".\")[0]\n",
    "            sep = folder_splitter\n",
    "            tsv_path = join(e, \"tables\")\n",
    "            tsv_name = \"All_data_\" + source + \".tsv\"\n",
    "            tsv = os.path.join(tsv_path, tsv_name)\n",
    "            data[source] = pd.read_csv(tsv, sep=\"\\t\")\n",
    "            tsv_name = \"EEG_data_\" + source + \".tsv\"\n",
    "            tsv = os.path.join(tsv_path, tsv_name)\n",
    "            EEG[source] = pd.read_csv(tsv, sep=\"\\t\")    \n",
    "            tsv_name = \"Semiology_data_\" + source + \".tsv\"\n",
    "            tsv = os.path.join(tsv_path, tsv_name)\n",
    "            Semio[source] = pd.read_csv(tsv, sep=\"\\t\")\n",
    "            tsv_name = \"Testing_data_\" + source + \".tsv\"\n",
    "            tsv = os.path.join(tsv_path, tsv_name)\n",
    "            Test[source] = pd.read_csv(tsv, sep=\"\\t\")\n",
    "            if source == \"grand_average\":\n",
    "                pass\n",
    "            else:\n",
    "                interactive_plots[source] = plot_interactive_subplot_with_table(data[source], EEG[source], \n",
    "                                                                            Semio[source], Test[source], title=source)\n",
    "                save_name = join(\"..\", \"results\", source, \"viz\", str(source + \"_interactive_viz.html\"))\n",
    "                if not os.path.isfile(save_name):\n",
    "                    save_plotly_to_html(interactive_plots[source], source=source)\n",
    "                    cap = source + \" VIZ --> seizure\"\n",
    "                    report.add_htmls_to_section(interactive_plots[source].to_html(full_html=False), \n",
    "                                                section=source, captions=cap)\n",
    "                # event counts (plot.ly)\n",
    "                event_counts = plot_interactive_eeg_and_semio(eeg=EEG[source], semio=Semio[source], source=source)\n",
    "                cap = source + \" VIZ --> event_conuts\"\n",
    "                sec = source\n",
    "                report.add_htmls_to_section(event_counts.to_html(full_html=False), section=sec, captions=cap)\n",
    "                # Testing\n",
    "                cap = source + \" VIZ --> Testing results\"\n",
    "                testing_viz = plot_interactive_testing_results(t_events=Test[source], title=cap)\n",
    "                report.add_htmls_to_section(testing_viz.to_html(full_html=False), section=sec, captions=cap)\n",
    "    # Save all\n",
    "    report_save_name = os.path.join(\"..\", \"results\", \"Single_seizures_report.html\")\n",
    "    report.save(report_save_name, overwrite=True)\n",
    "    # Plots/report for grand average\n",
    "    # Grand average report - original markers\n",
    "    ga_report = make_grand_average_report(df=data[\"grand_average\"], name=\"grand_average\", subj_name=subj_name)\n",
    "    report_save_name = os.path.join(\"..\", \"results\", \"Grand_average_report.html\")\n",
    "    ga_report.save(report_save_name, overwrite=True)\n",
    "    base_dir = os.path.join (\"..\", \"results\")\n",
    "    data[\"grand_average\"].to_csv(os.path.join(base_dir, \"Data_grand_average.tsv\"), sep=\"\\t\")\n",
    "    # Lazy grand average report  \n",
    "    lazy_df = data[\"grand_average\"].copy()\n",
    "    for idx, val in enumerate(lazy_df[\"description\"]):\n",
    "        lazy_df[\"description\"][idx] = _marker_to_text(val)\n",
    "    base_dir = os.path.join (\"..\", \"results\")\n",
    "    lazy_df.to_csv(os.path.join(base_dir, \"Lazy_grand_average.tsv\"), sep=\"\\t\")  \n",
    "    lazy_ga_report = make_grand_average_report(df=lazy_df, name=\"readable_grand_average\", subj_name=subj_name)\n",
    "    report_save_name = os.path.join(\"..\", \"results\", \"Readable_grand_average_report.html\")\n",
    "    lazy_ga_report.save(report_save_name, overwrite=True)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdcff35da2c6bcb2243fe51a8cb0ff18e7b93a9215ca9c510fc0ec1ef7f4e845"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "ca57fd24bf8c41466d0279834b30a380f702b7c8e5c2ff58aac71378b0b4eddf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
