{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('mne023': conda)"
  },
  "interpreter": {
   "hash": "b1cd69c6b6d0865d1f4b5680942a83809df5c99e655e7460a56d3837fd4af54b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "from mne import Report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from utils import (get_parent_dir, extract_lab_sec, loc_of_sep_lines, plot_seizure_horizontal, plot_seizure_vertical,\n",
    "                                        raw_to_df, extract_groups, extract_ordered_groups, save_plotly_to_html,\n",
    "                                        shrink_df_to_tmax, create_results_folders, save_fig_to_disc, plot_interactive_subplot_with_table,\n",
    "                                        extract_parameters_from_raw, plot_eventcounts, plot_interactive_tables)\n",
    "import plotly as py\n",
    "import ipywidgets as widgets\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "graph_sep_line_width = 5\n",
    "plot_tmin = 5\n",
    "plot_tmax = 60"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_parameters_from_raw(raw=None):\n",
    "    highp = raw.info[\"highpass\"]\n",
    "    lowp = raw.info[\"lowpass\"]\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    aq = raw.info[\"meas_date\"]\n",
    "    channels = raw.info[\"ch_names\"]\n",
    "    nr_channels = raw.info[\"nchan\"]\n",
    "    return highp, lowp, sfreq, aq, channels, nr_channels\n",
    "\n",
    "def raw_to_df(raw, edf=None):\n",
    "    df = pd.DataFrame(raw.annotations)\n",
    "    to_drop = [\"duration\"]\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    if \"Beginn\" in str(df[\"description\"]):\n",
    "        samp_beginn = df[df[\"description\"].str.contains(\"Beginn\")][\"onset\"]\n",
    "        onset = samp_beginn\n",
    "        if isinstance(samp_beginn, pd.core.series.Series):\n",
    "            print(f\"There are multiple markers for seizure onset in this file --> taking first one.\")\n",
    "            samp_beginn = samp_beginn.iloc[0]\n",
    "            onset = samp_beginn\n",
    "    else:\n",
    "        print(\"Error: No marker containing \\\"Beginn\\\" found, cannot determine seizure onset for file: \", edf)\n",
    "        print(\"Setting seizure onset to the beginning of the file\")\n",
    "        samp_beginn = 0\n",
    "        onset = \"No seizure onset was marked\"\n",
    "    df[\"time_from_onset\"] = df[\"onset\"] - float(samp_beginn)\n",
    "    df = df.drop([\"orig_time\"], axis=1)\n",
    "    return df, onset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "edfs = glob.glob(\"../data/*.edf\")\n",
    "e = edfs[0]\n",
    "e"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw = mne.io.read_raw(e)\n",
    "df, onset = raw_to_df(raw, e)\n",
    "e_events, s_events, t_events = extract_groups(df, e)\n",
    "e_events"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_eventcounts(df=None, eeg=None, semio=None, source=None):\n",
    "    fig, ax = plt.subplots(figsize=(15,26))\n",
    "    plt.suptitle(str(source) + \" - Event counts\")\n",
    "    #EEG\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax1.set_title(\"EEG Events\")\n",
    "    if len(eeg['description'].value_counts()) > 0:\n",
    "        sns.countplot(y=\"description\", data=eeg, orient=\"h\", ax=ax1, order = eeg['description'].value_counts().index)\n",
    "    else:\n",
    "        #plt.plot(x=1, y=1)\n",
    "        ax1.set_title(\"No EEG events found in file...\")\n",
    "    #Semiology\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    ax2.set_title(\"Semiology Events\")\n",
    "    if [semio['description'].value_counts()] != []:\n",
    "        sns.countplot(y=\"description\", data=semio, orient=\"h\", ax=ax2, order = semio['description'].value_counts().index)\n",
    "    else:\n",
    "        plt.plot(x=1, y=1)\n",
    "        ax2.set_title(\"No Semiology events found in file...\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_axis_off()\n",
    "    fig.subplots_adjust(hspace=0.2)\n",
    "    return fig\n",
    "\n",
    "fig = plot_eventcounts(df=df, eeg=e_events, semio=s_events, source=e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.to_csv(\"df_template.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "# Start from template df\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"df_template.csv\")\n",
    "e_events, s_events, t_events = extract_groups(df, \"Test_Dataframe\")\n",
    "e = \"test_folder\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import plotly.express as px\n",
    "def plot_interactive_eventcounts(eeg=None, semio=None, test=None, source=None):\n",
    "    fig = make_subplots(rows=3, cols=1, \n",
    "                        specs=[[{\"type\": \"bar\"}],\n",
    "                                [{\"type\": \"bar\"}],\n",
    "                                [{\"type\": \"bar\"}]],\n",
    "                        subplot_titles=(\"EEG events\", \"Semiology events\", \"Testing events\"),\n",
    "                        #row_width=[0.1, 0.1, 0.1],\n",
    "                        vertical_spacing=0.2\n",
    "                        )\n",
    "    # EEG\n",
    "    fig.add_trace(go.Histogram(y=e_events[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"EEG\"),\n",
    "                    row=1, col=1\n",
    "                    )\n",
    "\n",
    "    # Semio\n",
    "    fig.add_trace(go.Histogram(y=s_events[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"Semiology\"),\n",
    "                    row=2, col=1\n",
    "                    )    \n",
    "\n",
    "    # Test\n",
    "    fig.add_trace(go.Histogram(y=t_events[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"Testing\"),\n",
    "                    row=3, col=1\n",
    "                    )\n",
    "\n",
    "\n",
    "    fig.update_yaxes(categoryorder=\"total descending\")\n",
    "    fig.update_layout(width=1000, height=1200)\n",
    "    return fig\n",
    "\n",
    "plot_interactive_eventcounts(eeg=e_events, semio=s_events, test=t_events, source=\"Test\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_interactive_eeg_and_semio(eeg=None, semio=None, test=None, source=None):\n",
    "    fig = make_subplots(rows=1, cols=2, start_cell=\"top-left\",\n",
    "                        subplot_titles=(\"EEG events\", \"Semiology events\"),\n",
    "                        #row_width=[0.1, 0.1, 0.1],\n",
    "                        horizontal_spacing=0.2\n",
    "                        )\n",
    "    # EEG\n",
    "    fig.add_trace(go.Histogram(y=e_events[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"EEG\"),\n",
    "                    row=1, col=1\n",
    "                    )\n",
    "\n",
    "    # Semio\n",
    "    fig.add_trace(go.Histogram(y=s_events[\"description\"], \n",
    "                        histfunc=\"count\",\n",
    "                        orientation=\"h\",\n",
    "                        name=\"Semiology\"),\n",
    "                    row=1, col=2\n",
    "                    )    \n",
    "\n",
    "\n",
    "    fig.update_yaxes(categoryorder=\"total descending\")\n",
    "    fig.update_layout(width=1100, height=800)\n",
    "    return fig\n",
    "\n",
    "plot_interactive_eventcounts(eeg=e_events, semio=s_events, test=t_events, source=\"Test\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t_events"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_interactive_eventcount(df=None, mode=None, source=None):\n",
    "    fig = go.Figure(\n",
    "        data=[go.Histogram(y=df[\"description\"], \n",
    "                            histfunc=\"count\",\n",
    "                            orientation=\"h\")]\n",
    "                    )\n",
    "    fig.update_yaxes(categoryorder=\"total descending\")\n",
    "    fig.update_layout(title=(source + \" - \" + mode + \" - Eventcount\"))\n",
    "    return fig\n",
    "plot_interactive_eventcount(t_events, mode=\"Semiology\", source= \"asd\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----\n",
    "## Testing with failed/passed viz...\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_interactive_testing_results(t_events=None, title=\"Testing results\"):\n",
    "    t_events_failed = t_events[t_events[\"description\"].apply(lambda x: x.endswith(\"0\"))]\n",
    "    t_events_failed[\"description\"] = t_events_failed.description.str.split(\"0\").str[0]\n",
    "    t_events_passed = t_events[t_events[\"description\"].apply(lambda x: x.endswith(\"1\"))]\n",
    "    t_events_passed[\"description\"] = t_events_passed.description.str.split(\"1\").str[0]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # passed\n",
    "    fig.add_trace(go.Scatter(x=t_events_passed[\"time_from_onset\"], \n",
    "                        y=t_events_passed[\"description\"],\n",
    "                        name=\"passed\",\n",
    "                        mode=\"markers\")\n",
    "                    )\n",
    "\n",
    "    # failed\n",
    "    fig.add_trace(go.Scatter(x=t_events_failed[\"time_from_onset\"], \n",
    "                        y=t_events_failed[\"description\"],\n",
    "                        name=\"failed\",\n",
    "                        mode=\"markers\")\n",
    "                    )  \n",
    "\n",
    "    fig.update_layout(width=1100, height=800, title=title)\n",
    "    return fig\n",
    "\n",
    "fig = plot_interactive_testing_results(t_events, title=\"Test Test Test\")\n",
    "fig"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tabular data extraction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "from mne import Report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from utils import (get_parent_dir, extract_lab_sec, loc_of_sep_lines, plot_seizure_horizontal, plot_seizure_vertical,\n",
    "                                        extract_groups, \n",
    "                                        extract_ordered_groups, \n",
    "                                        save_plotly_to_html, \n",
    "                                        raw_to_df,\n",
    "                                        shrink_df_to_tmax, create_results_folders, save_fig_to_disc,\n",
    "                                        plot_interactive_subplot_with_table, extract_parameters_from_raw, \n",
    "                                        plot_eventcounts, plot_interactive_tables)\n",
    "import plotly as py\n",
    "import ipywidgets as widgets\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "graph_sep_line_width = 5\n",
    "plot_tmin = 5\n",
    "plot_tmax = 60\n",
    "\n",
    "win=False\n",
    "\n",
    "edfs = glob.glob(\"../data/*.edf\")\n",
    "create_results_folders(edfs)\n",
    "\n",
    "edfs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = dict() \n",
    "e_events = dict()\n",
    "s_events = dict()\n",
    "t_events = dict()\n",
    "for e in edfs:\n",
    "    print(f\"Now processing file: {e}\")\n",
    "    raw = mne.io.read_raw(e, preload=True)\n",
    "    df[e], onset = raw_to_df(raw, e)\n",
    "\n",
    "    if win:\n",
    "        e_events[e], s_events[e], t_events[e] = extract_ordered_groups(df[e], e.split(\"\\\\\")[-1])\n",
    "    else:\n",
    "        e_events[e], s_events[e], t_events[e] = extract_ordered_groups(df[e], e.split(\"/\")[-1]) \n",
    "    \n",
    "    #save\n",
    "    if win:\n",
    "        csv_path = os.path.join(\"..\", \"results\", e.split(\"\\\\\")[-1].split(\".\")[0], \"tables\")\n",
    "        e_file = e.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    else:\n",
    "        csv_path = os.path.join(\"..\", \"results\", e.split(\"/\")[-1].split(\".\")[0], \"tables\")\n",
    "        e_file = e.split(\"/\")[-1].split(\".\")[0]\n",
    "    csv_name = \"All_data_\" + e_file + \".csv\"\n",
    "    fname = os.path.join(csv_path, csv_name)\n",
    "    df[e].to_csv(fname, sep=\"\\t\")\n",
    "    csv_name = \"EEG_data_\" + e_file + \".csv\"\n",
    "    fname = os.path.join(csv_path, csv_name)\n",
    "    e_events[e].to_csv(fname, sep=\"\\t\")\n",
    "    csv_name = \"Semiology_data_\" + e_file + \".csv\"\n",
    "    fname = os.path.join(csv_path, csv_name)\n",
    "    s_events[e].to_csv(fname, sep=\"\\t\")\n",
    "    csv_name = \"Testing_data_\" + e_file + \".csv\"\n",
    "    fname = os.path.join(csv_path, csv_name)\n",
    "    t_events[e].to_csv(fname, sep=\"\\t\")    \n",
    "\n",
    "for idx, val in enumerate(df.keys()):\n",
    "    if idx == 0:\n",
    "        # all data vertical\n",
    "        vconcat = df[val]\n",
    "        # all data horizontal\n",
    "        concat = df[val]\n",
    "        source = \"source_\" + str(idx)\n",
    "        concat[source] = val\n",
    "        cols = list(concat)\n",
    "        cols.insert(0, cols.pop(cols.index(source)))\n",
    "        concat = concat.loc[:, cols]\n",
    "        concat = concat.sort_values(by=[\"time_from_onset\"])\n",
    "        if \"source\" in concat.keys():\n",
    "            concat.drop(columns=[\"source\"], axis=1, inplace=True)\n",
    "        concat[\"order_of_occurence\"] = (1 + np.arange(len(concat.loc[:,\"time_from_onset\"])))\n",
    "        # eeg, semio\n",
    "        eeg_ga, semio_ga, test_ga = e_events[val], s_events[val], t_events[val]  # should be same keys as for e in edfs...\n",
    "\n",
    "    if idx > 0:\n",
    "        # all data vertical\n",
    "        vnew_df = df[val]\n",
    "        vconcat = pd.concat([vconcat, vnew_df], axis=0)\n",
    "        # all data horizontal\n",
    "        new_df = df[val]\n",
    "        source = \"source_\" + str(idx)\n",
    "        new_df[source] = val\n",
    "        cols = list(new_df)\n",
    "        cols.insert(0, cols.pop(cols.index(source)))\n",
    "        new_df = new_df.loc[:, cols]\n",
    "        if \"source\" in new_df.keys():\n",
    "            new_df.drop(columns=[\"source\"], axis=1, inplace=True)\n",
    "        new_df[\"order_of_occurence\"] = (1 + np.arange(len(new_df.loc[:,\"time_from_onset\"]))).astype(int)\n",
    "        concat = pd.merge(concat, new_df, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "        # eeg, semio\n",
    "        ne, ns, nt = e_events[val], s_events[val], t_events[val]\n",
    "        eeg_ga = pd.merge(eeg_ga, ne, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \")) \n",
    "        semio_ga = pd.merge(semio_ga, ns, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "        test_ga = pd.merge(test_ga, nt, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "if \"source_0\" in vconcat.keys():\n",
    "    vconcat.drop(columns=[\"source_0\"], axis=1, inplace=True)\n",
    "\n",
    "# save grand averages\n",
    "if win:\n",
    "    eeg_ga.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\EEG_grand_average.tsv\", sep=\"\\t\")\n",
    "    semio_ga.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "    test_ga.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "    concat.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_events_horizontal.tsv\", sep=\"\\t\")\n",
    "    vconcat.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_events_vertical.tsv\", sep=\"\\t\")\n",
    "\n",
    "else:\n",
    "    eeg_ga.to_csv(\"../results/grand_average/tables/EEG_grand_average.tsv\", sep=\"\\t\")\n",
    "    semio_ga.to_csv(\"../results/grand_average/tables/Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "    test_ga.to_csv(\"../results/grand_average/tables/Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "    concat.to_csv(\"../results/grand_average/tables/All_events_horizontal.tsv\", sep=\"\\t\")\n",
    "    vconcat.to_csv(\"../results/grand_average/tables/All_data_grand_average.tsv\", sep=\"\\t\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grand average VIZ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import mne\n",
    "from mne import Report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from utils import (get_parent_dir, extract_lab_sec,\n",
    "                                        extract_ordered_groups, \n",
    "                                        save_plotly_to_html, \n",
    "                                        raw_to_df,\n",
    "                                        create_results_folders,\n",
    "                                        plot_interactive_subplot_with_table, \n",
    "                                        plot_interactive_tables)\n",
    "import plotly as py\n",
    "import ipywidgets as widgets\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "graph_sep_line_width = 5\n",
    "plot_tmin = 5\n",
    "plot_tmax = 60\n",
    "\n",
    "data = dict()\n",
    "EEG = dict()\n",
    "Semio = dict()\n",
    "Test = dict()\n",
    "\n",
    "data[\"grand_average\"] = pd.read_csv(\"../results/grand_average/tables/All_data_grand_average.tsv\", sep=\"\\t\")\n",
    "data[\"grand_average\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "e, s, t = extract_ordered_groups(data[\"grand_average\"])\n",
    "\n",
    "def plot_interactive_testing_results(t_events=None, title=\"Testing results\"):\n",
    "    t_events_failed = t_events[t_events[\"description\"].apply(lambda x: x.endswith(\"0\"))]\n",
    "    t_events_failed[\"description\"] = t_events_failed.description.str.split(\"0\").str[0]\n",
    "    t_events_passed = t_events[t_events[\"description\"].apply(lambda x: x.endswith(\"1\"))]\n",
    "    t_events_passed[\"description\"] = t_events_passed.description.str.split(\"1\").str[0]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # passed\n",
    "    fig.add_trace(go.Scatter(x=t_events_passed[\"time_from_onset\"], \n",
    "                        y=t_events_passed[\"description\"],\n",
    "                        name=\"passed\",\n",
    "                        mode=\"markers\",\n",
    "                        hovertext=t_events_passed[\"source\"])\n",
    "                    )\n",
    "\n",
    "    # failed\n",
    "    fig.add_trace(go.Scatter(x=t_events_failed[\"time_from_onset\"], \n",
    "                        y=t_events_failed[\"description\"],\n",
    "                        name=\"failed\",\n",
    "                        mode=\"markers\",\n",
    "                        hovertext=t_events_passed[\"source\"])\n",
    "                    )  \n",
    "\n",
    "    fig.update_layout(width=1100, height=800, title=title,\n",
    "                    xaxis_title=\"Time in seconds from onset\",\n",
    "                    yaxis_title=\"\")\n",
    "    return fig\n",
    "\n",
    "plot_interactive_testing_results(t)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import mne\n",
    "\n",
    "\n",
    "def raw_to_df(raw, edf=None):\n",
    "    df = pd.DataFrame(raw.annotations)\n",
    "    df = df.drop([\"duration\"], axis=1)\n",
    "    df = df.drop([\"orig_time\"], axis=1)\n",
    "\n",
    "    # Find/set Beginn-Marker:\n",
    "    e_beginning = df[['e-beginn' in x for x in df['description'].str.lower()]]\n",
    "    s_beginning = df[['s-beginn' in x for x in df['description'].str.lower()]]\n",
    "    the_beginning = pd.concat([e_beginning, s_beginning], axis=0)\n",
    "    if the_beginning.empty:\n",
    "        print(\"Error: No marker containing \\\"Beginn\\\" found, cannot determine seizure onset for file: \", edf)\n",
    "        print(\"Setting seizure onset to the beginning of the file\")\n",
    "        onset = \"No seizure onset was marked\"\n",
    "        df.loc[-1] = [0, \"_Beginn_(assumed)_\"]\n",
    "        df.index = df.index + 1\n",
    "        df = df.sort_index()\n",
    "        the_beginning.loc[1,:] = [0, \"_Beginn-(assumed)_\"]  \n",
    "    samp_beginn = the_beginning.iloc[0,0].astype(float)\n",
    "    onset = samp_beginn.astype(float)\n",
    "    time_from_onset = df[\"onset\"]\n",
    "    time_from_onset = time_from_onset  - samp_beginn\n",
    "    df[\"time_from_onset\"] = time_from_onset\n",
    "    df = df.drop([\"onset\"], axis = 1)\n",
    "    \n",
    "    # Add source column to the left\n",
    "    df[\"source\"] = edf.split(\"/\")[-1].split(\".edf\")[0]      # needs to be changed for windows still\n",
    "    cols = list(df)\n",
    "    cols.insert(0, cols.pop(cols.index('source')))\n",
    "    df = df.loc[:, cols]\n",
    "    print(f\"Onset in raw_to_df: {onset}\")\n",
    "    return df, onset\n",
    "\n",
    "def extract_ordered_groups(df=None):\n",
    "    #df = df.drop_duplicates(subset=[\"description\"], keep=\"first\")   # not doing this, as e- and s- events might reuccur!\n",
    "    e_events = df[df[\"description\"].str.startswith(\"e-\")]\n",
    "    e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
    "    s_events = df[df[\"description\"].str.startswith(\"s-\")]\n",
    "    s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
    "    t_events = df[~df[\"description\"].str.startswith(\"s-\")]\n",
    "    t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
    "    t_events[\"order_of_occurence\"] = (np.arange(len(t_events.axes[0])) +1).astype(int)\n",
    "    return e_events, s_events, t_events\n",
    "\n",
    "def calculate_statistics(df):\n",
    "    eeg, semio, _ = extract_ordered_groups(df)\n",
    "    e_beginning = df[['e-beginn' in x for x in df['description'].str.lower()]]\n",
    "    s_beginning = df[['s-beginn' in x for x in df['description'].str.lower()]]\n",
    "    the_beginning = pd.concat([e_beginning, s_beginning], axis=0)\n",
    "    print(f\"the_beginning: {the_beginning}\\n\\n\")\n",
    "\n",
    "    for x in df['description'].str.lower():\n",
    "        if x.startswith(\"e-begin\") in df['description'].str.lower():\n",
    "            e_beg = x\n",
    "    print(f\"e_beg = {e_beg}\")\n",
    "\n",
    "\n",
    "edfs = glob.glob(\"../data/*.edf\")\n",
    "\n",
    "for e in edfs:\n",
    "    raw = mne.io.read_raw_edf(e, verbose=\"WARNING\")\n",
    "    #print(raw.annotations.to_data_frame())\n",
    "    df, onset = raw_to_df(raw, edf=e)\n",
    "    calculate_statistics(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Onset in raw_to_df: 138.89\n",
      "the_beginning:                           source description  time_from_onset\n",
      "2  PP05071984_fbtc_15062020_1512    e-Beginn              0.0\n",
      "\n",
      "\n",
      "e_beg = m0l1\n",
      "Onset in raw_to_df: 800.29\n",
      "the_beginning:                            source description  time_from_onset\n",
      "46  PP05071984_fbtc_16082020_1710    e-Beginn              0.0\n",
      "\n",
      "\n",
      "e_beg = o2 ex\n",
      "Onset in raw_to_df: 157.12\n",
      "the_beginning:                           source description  time_from_onset\n",
      "3  PP05071984_fbtc_19082020_1202    e-Beginn              0.0\n",
      "\n",
      "\n",
      "e_beg = e-bipd\n",
      "Onset in raw_to_df: 2074.55\n",
      "the_beginning:                           source description  time_from_onset\n",
      "8  PP05071984_fbtc_16082020_2002    e-Beginn              0.0\n",
      "\n",
      "\n",
      "e_beg = bekommt medikamente schluckt nicht runt\n",
      "Onset in raw_to_df: 126.7\n",
      "the_beginning:                           source description  time_from_onset\n",
      "2  PP05071984_fbtc_15062020_2128    e-Beginn             0.00\n",
      "8  PP05071984_fbtc_15062020_2128    s-Beginn            27.05\n",
      "\n",
      "\n",
      "e_beg = geht auf wc\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Onset in raw_to_df: 276.55\n",
      "the_beginning:                           source description  time_from_onset\n",
      "9  PP05071984_fbtc_16082020_1725    e-Beginn              0.0\n",
      "\n",
      "\n",
      "e_beg = eeg-stop 3.4\n",
      "Onset in raw_to_df: 68.58\n",
      "the_beginning:                           source description  time_from_onset\n",
      "3  PP05071984_fbtc_19082020_1553    e-Beginn              0.0\n",
      "\n",
      "\n",
      "e_beg = takt. reiz 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n",
      "/tmp/ipykernel_21300/2904597752.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  e_events[\"order_of_occurence\"] = (np.arange(len(e_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_events[\"order_of_occurence\"] = (np.arange(len(s_events.axes[0])) +1).astype(int)\n",
      "/tmp/ipykernel_21300/2904597752.py:46: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  t_events = t_events[~df[\"description\"].str.startswith(\"e-\")]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}