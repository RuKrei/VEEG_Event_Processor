{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Rudi Kreidenhuber, <Rudi.Kreidenhuber@gmail.com>, \n",
    "License: BSD (3-clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "\n",
    "Create Tables for single seizure (just like grand average) ?\n",
    "\n",
    "EKG?\n",
    "\n",
    "Create a radar chart of EEG and Semiology signs (r/l hemisphere: front, temp, parietal, occipital) - https://plotly.com/python/radar-chart/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Video EEG Monitoring Annotation visualizer\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## Inputs:\n",
    " - .edf-files you wish to analyze go into ./data folder\n",
    "\n",
    "## Run:\n",
    " - Press play :-)\n",
    "\n",
    "## Outputs:\n",
    " - Found in results folder\n",
    " - Results for single files are put into a folder that matches the input-filename\n",
    "\n",
    "----\n",
    "\n",
    "## Howto:\n",
    " 1. **Mark Events in EEG file using the following prefixes:**\n",
    " - e- --> EEG marker\n",
    " - s- --> Semiology marker\n",
    " - no prefix --> Everything else (clinical tests during/ after seizure)\n",
    " - i- --> Marker to ignore for focused analysis\n",
    "\n",
    " - One marker **must (!) contain \"Beginn\"** --> this is considered the seizure onset (if it is missing, onset is set to zero)\n",
    " - every marker **can** contain Beginn, for example:\n",
    " - Onset first seen in EEG --> Markername \"e-asdBeginnfgh\" --> would still be recognized as EEG marker and seizure onset\n",
    " 2. **Save EEG file in .edf format and copy to ./data folder**\n",
    " - Every file in this folder is going to be analyzed, if it ends with .edf\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Configuration\n",
    "----\n",
    "\n",
    "### Parameters:\n",
    "graph_sep_line_width\n",
    "- How far blue dashed seperator lines are apart from each other\n",
    "\n",
    "plot_tmin\n",
    "- First time point in seconds from onset, that should be included in the visualization, set to 0 to deactivate\n",
    "\n",
    "plot_tmax\n",
    "- Last time point in seconds from onset, that should be included in the visualization, set to 0 to deactivate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_name = \"Test-Patient\"\n",
    "graph_sep_line_width = 5\n",
    "plot_tmin = -20\n",
    "plot_tmax = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Pipeline start\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "edfs found:\n",
      " ['..\\\\data\\\\PC19012021_F1.edf', '..\\\\data\\\\PC19012021_F2.edf', '..\\\\data\\\\PC19012021_F3.edf']\n",
      "Embedding : jquery.js\n",
      "Embedding : jquery-ui.min.js\n",
      "Embedding : bootstrap.min.js\n",
      "Embedding : jquery-ui.min.css\n",
      "Embedding : bootstrap.min.css\n"
     ]
    }
   ],
   "source": [
    "# import everything\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import mne\n",
    "from mne import Report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from utils import (get_parent_dir, extract_lab_sec, loc_of_sep_lines, plot_seizure_horizontal, \n",
    "                                        plot_seizure_vertical, raw_to_df, extract_groups, \n",
    "                                        extract_ordered_groups, save_plotly_to_html,\n",
    "                                        shrink_df_to_tmax, create_results_folders, \n",
    "                                        save_fig_to_disc, plot_interactive_subplot_with_table,\n",
    "                                        extract_parameters_from_raw, plot_eventcounts, plot_interactive_tables,\n",
    "                                        plot_interactive_eeg_and_semio, plot_interactive_eventcount,\n",
    "                                        plot_interactive_testing_results, win_save_fig_to_disc, win_create_results_folders)\n",
    "import plotly as py\n",
    "import ipywidgets as widgets\n",
    "import plotly.io as pio\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "win = True\n",
    "\n",
    "# no need to show figures here\n",
    "plt.ioff() \n",
    "\n",
    "# grab .edfs\n",
    "edfs = glob.glob(\"../data/*.edf\")\n",
    "if win:\n",
    "    edfs = glob.glob(\"..\\\\data\\\\*.edf\")\n",
    "\n",
    "print(\"edfs found:\\n\", edfs)\n",
    "\n",
    "report = Report(subject=subj_name, title=\"Event summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Now processing file: ..\\data\\PC19012021_F1.edf\n",
      "Extracting EDF parameters from c:\\Users\\User\\Desktop\\VEEG_Event_Processor-main\\data\\PC19012021_F1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 122111  =      0.000 ...   476.996 secs...\n",
      "Error: No marker containing \"Beginn\" found, cannot determine seizure onset for file:  ..\\data\\PC19012021_F1.edf\n",
      "Setting seizure onset to the beginning of the file\n",
      "\n",
      "Calculating parameters for focused visualization, tmin = -20, tmax = 100 s.\n",
      "\n",
      "\n",
      "\n",
      "Now processing file: ..\\data\\PC19012021_F2.edf\n",
      "Extracting EDF parameters from c:\\Users\\User\\Desktop\\VEEG_Event_Processor-main\\data\\PC19012021_F2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 85247  =      0.000 ...   332.996 secs...\n",
      "Error: No marker containing \"Beginn\" found, cannot determine seizure onset for file:  ..\\data\\PC19012021_F2.edf\n",
      "Setting seizure onset to the beginning of the file\n",
      "\n",
      "Calculating parameters for focused visualization, tmin = -20, tmax = 100 s.\n",
      "\n",
      "\n",
      "\n",
      "Now processing file: ..\\data\\PC19012021_F3.edf\n",
      "Extracting EDF parameters from c:\\Users\\User\\Desktop\\VEEG_Event_Processor-main\\data\\PC19012021_F3.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 429055  =      0.000 ...  1675.996 secs...\n",
      "samp_beginn =  17    1461.29\n",
      "Name: onset, dtype: float64\n",
      "There are multiple markers for seizure onset in this file --> taking first one.\n",
      "\n",
      "Calculating parameters for focused visualization, tmin = -20, tmax = 100 s.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(edfs) > 0:\n",
    "    # Create folder structure\n",
    "    if win:\n",
    "        win_create_results_folders(edfs)\n",
    "    else:\n",
    "        create_results_folders(edfs)\n",
    "    df = dict() \n",
    "    shrinked_df = dict()\n",
    "    for e in edfs:\n",
    "        print(f\"Now processing file: {e}\")\n",
    "        raw = mne.io.read_raw(e, preload=True)                      #read\n",
    "        df[e], onset = raw_to_df(raw, e)                            # annotations to DataFrame\n",
    "        if win:\n",
    "            e_events, s_events, t_events = extract_ordered_groups(df[e], e.split(\"\\\\\")[-1])\n",
    "        else:\n",
    "            e_events, s_events, t_events = extract_ordered_groups(df[e], e.split(\"/\")[-1])     # Extract groups\n",
    "\n",
    "        # save\n",
    "        \n",
    "        #### windows paths...\n",
    "        if win:\n",
    "            source = e.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "            save_path = join(\"..\", \"results\", source, \"tables\", \"All_events.tsv\")\n",
    "            df[e].to_csv(save_path, sep=\"\\t\")\n",
    "            save_path = join(\"..\", \"results\", source, \"tables\", \"EEG_events.tsv\")\n",
    "            e_events.to_csv(save_path, sep=\"\\t\")\n",
    "            save_path = join(\"..\", \"results\", source, \"tables\", \"Semiology_events.tsv\")\n",
    "            s_events.to_csv(save_path, sep=\"\\t\")\n",
    "            save_path = join(\"..\", \"results\", source, \"tables\", \"Testing_events.tsv\")\n",
    "            t_events.to_csv(save_path, sep=\"\\t\")\n",
    "\n",
    "        \n",
    "        else:\n",
    "            source = e.split(\"/\")[-1].split(\".\")[0]\n",
    "            save_path = (\"../results/\" + source + \"/\" + \"tables/All_events.tsv\")\n",
    "            df[e].to_csv(save_path, sep=\"\\t\")\n",
    "            save_path = (\"../results/\" + source + \"/\" + \"tables/EEG_events.tsv\")\n",
    "            e_events.to_csv(save_path, sep=\"\\t\")\n",
    "            save_path = (\"../results/\" + source + \"/\" + \"tables/Semiology_events.tsv\")\n",
    "            s_events.to_csv(save_path, sep=\"\\t\")\n",
    "            save_path = (\"../results/\" + source + \"/\" + \"tables/Test_events.tsv\")\n",
    "            t_events.to_csv(save_path, sep=\"\\t\")\n",
    "                \n",
    "        # Shrink df to tmax\n",
    "        if df[e].iloc[0,0]:\n",
    "            print(f\"\\nCalculating parameters for focused visualization, tmin = {plot_tmin}, tmax = {plot_tmax} s.\\n\\n\\n\")\n",
    "            \n",
    "            shrinked_df[e] = shrink_df_to_tmax(df=df[e], tmax=plot_tmax, tmin=plot_tmin)\n",
    "            se_events, ss_events, st_events = extract_groups(shrinked_df[e], e)\n",
    "\n",
    "            # Visualizations\n",
    "            # vertical static\n",
    "            seizure_vertical_w_limits = plot_seizure_vertical(df=shrinked_df[e], eeg=se_events, \n",
    "                                                                semio=ss_events, testing=st_events, \n",
    "                                                                source=e.split(\"/\")[-1], tmin= plot_tmin, \n",
    "                                                                tmax=plot_tmax, name=\"seizure vertical with time limits\",\n",
    "                                                                graph_sep_line_width=graph_sep_line_width)\n",
    "            if win:\n",
    "                win_save_fig_to_disc(seizure_vertical_w_limits, e, \"seizure_vertical_with_limits\")\n",
    "            else:\n",
    "                save_fig_to_disc(seizure_vertical_w_limits, e, \"seizure_vertical_with_limits\")\n",
    "\n",
    "            # horizontal static\n",
    "            seizure_horizontal_w_limits = plot_seizure_horizontal(df=shrinked_df[e], eeg=se_events, \n",
    "                                                                semio=ss_events, testing=st_events, \n",
    "                                                                source=e.split(\"/\")[-1], tmin= plot_tmin, \n",
    "                                                                tmax=plot_tmax, name=\"seizure horizontal with time limits\",\n",
    "                                                                graph_sep_line_width=graph_sep_line_width)\n",
    "            if win:\n",
    "                win_save_fig_to_disc(seizure_vertical_w_limits, e, \"seizure_horizontal_w_limits\")\n",
    "            else:           \n",
    "                save_fig_to_disc(seizure_horizontal_w_limits, e, \"seizure_horizontal_w_limits\")\n",
    "\n",
    "            # event counts (plot.ly)\n",
    "            event_counts = plot_interactive_eeg_and_semio(eeg=se_events, semio=ss_events, \n",
    "                                                                source=e.split(\"/\")[-1])\n",
    "            cap = source + \" VIZ --> event counts (with limits)\"\n",
    "            sec = source\n",
    "            report.add_htmls_to_section(event_counts.to_html(full_html=False), section=sec, captions=cap)\n",
    "\n",
    "\n",
    "        # vertical static\n",
    "        seizure_vertical = plot_seizure_vertical(df=df[e], eeg=e_events, semio=s_events, \n",
    "                                                    testing=t_events, source=e.split(\"/\")[-1], \n",
    "                                                    name=\"seizure vertical\",\n",
    "                                                    graph_sep_line_width=graph_sep_line_width)\n",
    "        if win:\n",
    "            win_save_fig_to_disc(seizure_vertical_w_limits, e, \"seizure_vertical\")\n",
    "        else:           \n",
    "            save_fig_to_disc(seizure_vertical, e, \"seizure_vertical\")\n",
    "\n",
    "        # horizontal static\n",
    "        seizure_horizontal = plot_seizure_horizontal(df=df[e], eeg=e_events, semio=s_events, \n",
    "                                                    testing=t_events, source=e.split(\"/\")[-1], \n",
    "                                                    name=\"seizure_horizontal\",\n",
    "                                                    graph_sep_line_width=graph_sep_line_width)\n",
    "        if win:\n",
    "            win_save_fig_to_disc(seizure_vertical_w_limits, e, \"seizure_horizontal\")\n",
    "        else:\n",
    "            save_fig_to_disc(seizure_horizontal, e, \"seizure_horizontal\")\n",
    "\n",
    "        # event counts (plot.ly)\n",
    "        source=e.split(\"/\")[-1].split(\".edf\")[0]\n",
    "        if win:\n",
    "            source=e.split(\"\\\\\")[-1].split(\".edf\")[0]\n",
    "        event_counts = plot_interactive_eeg_and_semio(eeg=e_events, semio=s_events, source=source)\n",
    "        cap = source + \" VIZ --> event_conuts\"\n",
    "        sec = source\n",
    "        report.add_htmls_to_section(event_counts.to_html(full_html=False), section=sec, captions=cap)\n",
    "\n",
    "        # Testing\n",
    "        cap = source + \" VIZ --> Testing results\"\n",
    "        testing_viz = plot_interactive_testing_results(t_events=t_events, title=cap)\n",
    "        report.add_htmls_to_section(testing_viz.to_html(full_html=False), section=sec, captions=cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Save data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       0.00\n1     162.36\n2     171.36\n3     171.40\n4     174.24\n5     175.97\n6     177.37\n7     177.43\n8     178.57\n9     184.70\n10    185.34\n11    187.43\n12    188.38\n13    188.71\n14    190.98\n15    191.68\n16    192.21\n17    196.65\n18    208.65\n19    210.45\n20    221.80\n21    229.30\n22    236.20\n23    240.69\n24    245.32\n25    257.46\n26    264.38\n27    274.11\n28    281.21\n29    286.62\n30    307.15\n31    319.16\n32    322.43\n33    326.28\n34    328.96\n35    333.35\n36    340.30\n37    347.13\n38    351.52\n39    357.25\n40    366.04\n41    371.74\n42    395.43\n43    398.16\n44    402.96\n45    408.64\n46    424.96\n47    433.49\n48    442.88\n49    446.58\nName: time_from_onset, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_keys = df.keys()\n",
    "# horizontal grand average\n",
    "for idx, val in enumerate(df_keys):\n",
    "    if idx == 0:\n",
    "        concat = df[val]\n",
    "        concat[\"source\"] = val\n",
    "        cols = list(concat)\n",
    "        if not \"source\" in concat:\n",
    "            cols.insert(0, cols.pop(cols.index('source')))\n",
    "        concat = concat.loc[:, cols]\n",
    "        print(concat.time_from_onset)\n",
    "        concat = concat.sort_values(by=[\"time_from_onset\"])\n",
    "        concat = concat.drop(columns=[\"onset\"], axis=1)\n",
    "        concat[\"order_of_occurence\"] = (1 + np.arange(len(concat.loc[:,\"time_from_onset\"])))\n",
    "        \n",
    "    if idx > 0:\n",
    "        new_df = df[val]\n",
    "        if not \"source\" in new_df.keys():\n",
    "            new_df[\"source\"] = val\n",
    "        cols = list(new_df)\n",
    "        cols.insert(0, cols.pop(cols.index('source')))\n",
    "        new_df = new_df.loc[:, cols]\n",
    "        new_df.drop(columns=[\"onset\"], axis=1, inplace=True)\n",
    "        new_df[\"order_of_occurence\"] = (1 + np.arange(len(new_df.loc[:,\"time_from_onset\"]))).astype(int)\n",
    "        concat = pd.merge(concat, new_df, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "    #print(f\"\\n\\n\\n\\nRun {idx} --> concat = {concat}\")\n",
    "    idx += 1\n",
    "\n",
    "if win:\n",
    "    concat.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_Data_horizontal.tsv\", sep=\"\\t\")\n",
    "else:\n",
    "    concat.to_csv(\"../results/grand_average/tables/All_Data_horizontal.tsv\", sep=\"\\t\")\n",
    "\n",
    "# EEG/Semio/Test horizontal grand_average\n",
    "for idx, val in enumerate(df_keys):\n",
    "    if idx == 0:\n",
    "        eeg_ga, semio_ga, test_ga = extract_ordered_groups(df[val], source = val)\n",
    "        # this should not be necessary:\n",
    "        eeg_ga.sort_values(by=[\"time_from_onset\"])\n",
    "        semio_ga.sort_values(by=[\"time_from_onset\"])\n",
    "        test_ga.sort_values(by=[\"time_from_onset\"])\n",
    "        \n",
    "    if idx > 0:\n",
    "        new_df = df[val]\n",
    "        ne, ns, nt = extract_ordered_groups(new_df, source = val)\n",
    "        #new_df.insert(loc=0, column='source', value=val.split(\"/\")[-1])\n",
    "        eeg_ga = pd.merge(eeg_ga, ne, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \")) \n",
    "        semio_ga = pd.merge(semio_ga, ns, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "        test_ga = pd.merge(test_ga, nt, how=\"outer\", on=\"description\", suffixes=(\" \", \"  \"))\n",
    "    idx += 1\n",
    "\n",
    "# drop onset columns\n",
    "to_keep = [c for c in eeg_ga.columns if not c.lower().startswith(\"onse\")]\n",
    "eeg_ga = eeg_ga[to_keep]\n",
    "to_keep = [c for c in semio_ga.columns if not c.lower().startswith(\"onse\")]\n",
    "semio_ga = semio_ga[to_keep]\n",
    "to_keep = [c for c in test_ga.columns if not c.lower().startswith(\"onse\")]\n",
    "test_ga = test_ga[to_keep]\n",
    "\n",
    "if win:\n",
    "    eeg_ga.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\EEG_grand_average.tsv\", sep=\"\\t\")\n",
    "    semio_ga.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "    test_ga.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "else:\n",
    "    eeg_ga.to_csv(\"../results/grand_average/tables/EEG_grand_average.tsv\", sep=\"\\t\")\n",
    "    semio_ga.to_csv(\"../results/grand_average/tables/Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "    test_ga.to_csv(\"../results/grand_average/tables/Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "# Vertical grand average\n",
    "for idx, val in enumerate(df_keys):\n",
    "    if idx == 0:\n",
    "        concat = df[val]\n",
    "        concat.loc[:, \"source\"] = val.split(\"/\")[-1]        \n",
    "    if idx > 0:\n",
    "        new_df = df[val]\n",
    "        new_df.loc[:, \"source\"] = val.split(\"/\")[-1]\n",
    "        concat = pd.concat([concat, new_df], axis=0)     \n",
    "    idx += 1\n",
    "concat.drop(columns=[\"onset\"], axis=1)\n",
    "concat.drop(index=4, axis=1, inplace=True)\n",
    "\n",
    "concat = concat.sort_values(by=[\"time_from_onset\"])\n",
    "\n",
    "if win:\n",
    "    concat.to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_events.tsv\", sep=\"\\t\")\n",
    "else:\n",
    "    concat.to_csv(\"../results/grand_average/tables/All_events.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "source": [
    "----\n",
    "# Interactive Visualization\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving report to location C:\\Users\\User\\Desktop\\VEEG_Event_Processor-main\\results\\cumulative_report.html\n",
      "Rendering : Table of Contents\n",
      "PC19012021_F1\n",
      " ... PC19012021_F1 VIZ --> event counts (with limits)\n",
      " ... PC19012021_F1 VIZ --> event_conuts\n",
      " ... PC19012021_F1 VIZ --> Testing results\n",
      " ... PC19012021_F1 --> interactive Viz\n",
      "PC19012021_F2\n",
      " ... PC19012021_F2 VIZ --> event counts (with limits)\n",
      " ... PC19012021_F2 VIZ --> event_conuts\n",
      " ... PC19012021_F2 VIZ --> Testing results\n",
      " ... PC19012021_F2 --> interactive Viz\n",
      "PC19012021_F3\n",
      " ... PC19012021_F3 VIZ --> event counts (with limits)\n",
      " ... PC19012021_F3 VIZ --> event_conuts\n",
      " ... PC19012021_F3 VIZ --> Testing results\n",
      " ... PC19012021_F3 --> interactive Viz\n",
      " ... grand_average --> Testing results\n",
      "grand_average\n",
      " ... grand_average --> interactive Viz\n",
      " ... grand_average --> Tabular data\n",
      " ... grand_average --> Tabular data - order only\n",
      " ... grand_average --> EEG event_counts\n",
      " ... grand_average --> Semiology event_counts\n",
      " ... grand_average --> Testing event_counts\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Desktop\\\\VEEG_Event_Processor-main\\\\results\\\\cumulative_report.html'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Seizure subplots\n",
    "event_folders = glob.glob(\"../results/*\")\n",
    "if win:\n",
    "    event_folders = glob.glob(\"..\\\\results\\\\*\")\n",
    "data = dict()\n",
    "interactive_plots = dict()\n",
    "for e in event_folders:\n",
    "    if win:\n",
    "        source = e.split(\"\\\\\")[-1]\n",
    "    else:\n",
    "        source = e.split(\"/\")[-1]\n",
    "    tsv = join(e, \"tables\", \"All_events.tsv\")\n",
    "    data[source] = pd.read_csv(tsv, sep=\"\\t\")\n",
    "    EEG, Semio, Test = extract_ordered_groups(data[source], source)\n",
    "    interactive_plots[source] = plot_interactive_subplot_with_table(data[source], EEG, Semio, Test, title=source)\n",
    "    save_name = join(\"..\", \"results\", source, \"viz\", str(source + \"_interactive_viz.html\"))\n",
    "    if not os.path.isfile(save_name):\n",
    "        save_plotly_to_html(interactive_plots[source], source=source)\n",
    "        cap = source + \" --> interactive Viz\"\n",
    "        report.add_htmls_to_section(interactive_plots[source].to_html(full_html=False), section=source, captions=cap)\n",
    "\n",
    "\n",
    "# grand averages\n",
    "if win:\n",
    "    ga_h = pd.read_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_Data_horizontal.tsv\", sep=\"\\t\")\n",
    "    EEG_ga = pd.read_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\EEG_grand_average.tsv\", sep=\"\\t\")\n",
    "    semio_ga = pd.read_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "    test_ga = pd.read_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "    all_events_vert = pd.read_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_events.tsv\", sep=\"\\t\")\n",
    "\n",
    "else:\n",
    "    ga_h = pd.read_csv(\"../results/grand_average/tables/All_Data_horizontal.tsv\", sep=\"\\t\")\n",
    "    EEG_ga = pd.read_csv(\"../results/grand_average/tables/EEG_grand_average.tsv\", sep=\"\\t\")\n",
    "    semio_ga = pd.read_csv(\"../results/grand_average/tables/Semiology_grand_average.tsv\", sep=\"\\t\")\n",
    "    test_ga = pd.read_csv(\"../results/grand_average/tables/Testing_grand_average.tsv\", sep=\"\\t\")\n",
    "    all_events_vert = pd.read_csv(\"../results/grand_average/tables/All_events.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Interactive plots\n",
    "# Grand average - with times\n",
    "ga_fig = plot_interactive_tables(ga_h, EEG_ga, semio_ga, test_ga)\n",
    "source=\"grand_average\"\n",
    "cap = source + \" --> Tabular data\"\n",
    "report.add_htmls_to_section(ga_fig.to_html(full_html=False), section=source, captions=cap)\n",
    "\n",
    "# Grand average - order only\n",
    "to_keep = [c for c in ga_h.columns if not c.lower().startswith(\"time\")]\n",
    "to_keep = [c for c in to_keep if not c.lower().startswith(\"unnam\")]\n",
    "if win:\n",
    "    ga_h[to_keep].to_csv(\"..\\\\results\\\\grand_average\\\\tables\\\\All_events_order_only.csv\", sep=\"\\t\")\n",
    "else:\n",
    "    ga_h[to_keep].to_csv(\"../results/grand_average/tables/All_events_order_only.csv\", sep=\"\\t\")\n",
    "oga_fig = plot_interactive_tables(ga_h[to_keep], EEG_ga[to_keep], semio_ga[to_keep], test_ga[to_keep])\n",
    "source=\"grand_average\"\n",
    "cap = source + \" --> Tabular data - order only\"\n",
    "report.add_htmls_to_section(oga_fig.to_html(full_html=False), section=\"grand_average\", captions=cap)\n",
    "\n",
    "\n",
    "\n",
    "# Grand average - Event counts\n",
    "EEG, Semio, Test = extract_ordered_groups(all_events_vert, source=source)\n",
    "source = \"grand_average\"\n",
    "cap = source + \" --> EEG event_counts\"\n",
    "eeg_counts = plot_interactive_eventcount(df=EEG, mode=\"EEG\", source=source)\n",
    "report.add_htmls_to_section(eeg_counts.to_html(full_html=False), section=source, captions=cap)\n",
    "\n",
    "cap = source + \" --> Semiology event_counts\"\n",
    "semio_counts = plot_interactive_eventcount(df=Semio, mode=\"Semiology\", source=source)\n",
    "report.add_htmls_to_section(semio_counts.to_html(full_html=False), section=source, captions=cap)\n",
    "\n",
    "cap = source + \" --> Testing event_counts\"\n",
    "test_counts = plot_interactive_eventcount(df=Test, mode=\"Testing\", source=source)\n",
    "report.add_htmls_to_section(test_counts.to_html(full_html=False), section=source, captions=cap)\n",
    "\n",
    "cap = source + \" --> Testing results\"\n",
    "sec=\"grand_average\"\n",
    "testing_viz = plot_interactive_testing_results(t_events=Test, title=cap)\n",
    "report.add_htmls_to_section(testing_viz.to_html(full_html=False), section=sec, captions=cap)\n",
    "\n",
    "# Save all\n",
    "report_save_name = \"../results/cumulative_report.html\"\n",
    "if win:\n",
    "    report_save_name = \"..\\\\results\\\\cumulative_report.html\"\n",
    "report.save(report_save_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('mne': conda)",
   "metadata": {
    "interpreter": {
     "hash": "627af05cf1b9fcc3f9bfaafbaffa00c3448ce664a851a976ce5109514d67a251"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}